% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LogisticRMoE.R
\name{LogisticRMoE}
\alias{LogisticRMoE}
\title{Penalized MLE for the logistic regularized Mixture of Experts.}
\usage{
LogisticRMoE(Xmat, Ymat, K, Lambda, Gamma, option)
}
\arguments{
\item{Xmat}{The matrix data for the input.}

\item{Ymat}{Vector of the response variable.}

\item{K}{Number of expert classes.}

\item{Lambda}{Penalty value for the expert part.}

\item{Gamma}{Penalty value for the gating network.}

\item{option}{\code{option = 1}: using proximal Newton-type method;
\code{option = 0}: using proximal Newton method.}
}
\value{
LogisticRMoE returns an object of class \link{LRMoE}.
}
\description{
This function provides a penalized MLE for the logistic regularized Mixture
of Experts (MoE) model corresponding with the penalty parameters Lambda,
Gamma.
}
\seealso{
\link{LRMoE}
}
