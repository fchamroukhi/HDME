% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PoissonRMoE.R
\name{PoissonRMoE}
\alias{PoissonRMoE}
\title{Penalized MLE for the Poisson regularized Mixture of Experts.}
\usage{
PoissonRMoE(Xmat, Ymat, K, Lambda, Gamma, option = FALSE,
  verbose = TRUE)
}
\arguments{
\item{Xmat}{Matrix of explanatory variables. Each feature should be
standardized to have mean 0 and variance 1. One must add the column vector
(1,1,...,1) for the intercept variable.}

\item{Ymat}{Vector of the response variable. For the Gaussian case Y should
be standardized. For multi-logistic model Y is numbered from 1 to R (R is
the number of labels of Y).}

\item{K}{Number of experts (K > 1).}

\item{Lambda}{Penalty value for the experts.}

\item{Gamma}{Penalty value for the gating network.}

\item{option}{Optional. \code{option = TRUE}: using proximal Newton-type method;
\code{option = FALSE}: using proximal Newton method.}

\item{verbose}{Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during EM iterations.}
}
\value{
PoissonRMoE returns an object of class \link{PRMoE}.
}
\description{
This function provides a penalized MLE for the Poisson regularized Mixture
of Experts (MoE) model corresponding with the penalty parameters Lambda,
Gamma.
}
\seealso{
\link{PRMoE}
}
